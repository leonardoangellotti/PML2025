{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1372465f",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/r-doz/PML2025/blob/main/./04_exact_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact inference with Belief Propagation\n",
    "\n",
    "This notebook is inspired from [Jessica Stringham's work](https://jessicastringham.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to perform inference through the sum-product message passing, or belief propagation, on tree-like factor graphs (without any loop). We work only with discrete distributions and without using ad-hoc libraries, to better understand the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability distributions\n",
    "\n",
    "First of all, we need to represent a discrete probability distribution and check that it is normalized.\n",
    "For example, we can represent a discrete conditional distribution $p(v_1 | h_1)$ with a 2D array, as:\n",
    "\n",
    "|   | $h_1=a$ | $h_1=b$ | $h_1=c$|\n",
    "|---|-----|-----|----|\n",
    "| $v_1=0$ | 0.4  | 0.8  | 0.9|\n",
    "| $v_1=1$ | 0.6 | 0.2  | 0.1|\n",
    "\n",
    "We can build a class for the distributions containing the arrays and the labels of the axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution():\n",
    "\n",
    "    \"\"\"\"\n",
    "    Discrete probability distributions, expressed using labeled arrays\n",
    "    probs: array of probability values\n",
    "    axes_labels: list of axes names\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, probs, axes_labels):\n",
    "        self.probs = probs\n",
    "        self.axes_labels = axes_labels\n",
    "\n",
    "    def get_axes(self):\n",
    "        # returns a dictionary with axes names and the corresponding coordinates\n",
    "        return {name: axis for axis, name in enumerate(self.axes_labels)}\n",
    "    \n",
    "    def get_other_axes_from(self, axis_label):\n",
    "        # returns a tuple containing all the axes except from axis_label\n",
    "        return tuple(axis for axis, name in enumerate(self.axes_labels) if name != axis_label)\n",
    "    \n",
    "    def is_valid_conditional(self, variable_name):\n",
    "        # variable_name is the name of the variable for which we are computing the distribution, e.g. in p(y|x) it is 'y'\n",
    "        return np.all(np.isclose(np.sum(self.probs, axis=self.get_axes()[variable_name]), 1.0))\n",
    "    \n",
    "    def is_valid_joint(self):\n",
    "        return np.all(np.isclose(np.sum(self.probs), 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is p(v1|h1) a valid conditional distribution?  True\n",
      "Is p(v1|h1) a valid joint distribution?  False\n",
      "Is p(h1) a valid conditional distribution?  True\n",
      "Is p(h1) a valid joint distribution?  True\n",
      "Is p(v1|h1, h2) a valid conditional distribution?  True\n",
      "Is p(v1|h1, h2) a valid joint distribution?  False\n"
     ]
    }
   ],
   "source": [
    "# Let's see the previous distribution:\n",
    "\n",
    "p_v1_given_h1 = Distribution(np.array([[0.4, 0.8, 0.9], [0.6, 0.2, 0.1]]), ['v1', 'h1'])\n",
    "\n",
    "print('Is p(v1|h1) a valid conditional distribution? ', p_v1_given_h1.is_valid_conditional('v1'))\n",
    "print('Is p(v1|h1) a valid joint distribution? ', p_v1_given_h1.is_valid_joint())\n",
    "\n",
    "# Consider also a joint distribution and a conditional distribution with more than one 'given' variables\n",
    "\n",
    "p_h1 = Distribution(np.array([0.6, 0.3, 0.1]), ['h1'])\n",
    "\n",
    "print('Is p(h1) a valid conditional distribution? ', p_h1.is_valid_conditional('h1'))\n",
    "print('Is p(h1) a valid joint distribution? ', p_h1.is_valid_joint())\n",
    "\n",
    "p_v1_given_h0_h1 = Distribution(np.array([[[0.9, 0.2, 0.7], [0.3, 0.2, 0.5]],[[0.1, 0.8, 0.3], [0.7, 0.8, 0.5]]]), ['v1', 'h0', 'h1'])\n",
    "print('Is p(v1|h1, h2) a valid conditional distribution? ', p_v1_given_h0_h1.is_valid_conditional('v1'))\n",
    "print('Is p(v1|h1, h2) a valid joint distribution? ', p_v1_given_h0_h1.is_valid_joint())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to allow multiplications between distributions like $p(v_1|h_1,...,h_n) p(h_i)$, where $p(h_i)$ is a 1D array.\n",
    "To do it, we can exploit broadcasting. But first, we need to reshape $p(h_i)$ accordingly to the dimension $h_i$ of the distribution $p(v_1|h_1,...,h_n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(p_v_given_h, p_hi):\n",
    "    ''' \n",
    "    Compute the product of the distributions p(v|h1,..,hn)p(hi) where p(hi) is a 1D array\n",
    "    '''\n",
    "\n",
    "    # Get the axis corresponding to hi in the conditional distribution\n",
    "    axis = p_v_given_h.get_axes()[next(iter(p_hi.get_axes()))]\n",
    "\n",
    "    # Reshape p(hi) in order to exploit broadcasting. Consider also the case in which p(hi) is a scalar.\n",
    "    if p_hi.probs.shape != ():  # Check if p_hi is not a scalar\n",
    "        reshaped_p_hi = p_hi.probs.reshape([-1 if i == axis else 1 for i in range(p_v_given_h.probs.ndim)])\n",
    "    else:\n",
    "        reshaped_p_hi = p_hi.probs  # Scalar, no reshaping needed\n",
    "\n",
    "    return Distribution(p_v_given_h.probs * reshaped_p_hi, p_v_given_h.axes_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24 0.24 0.09]\n",
      " [0.36 0.06 0.01]]\n",
      "True\n",
      "[[[0.54 0.06 0.07]\n",
      "  [0.18 0.06 0.05]]\n",
      "\n",
      " [[0.06 0.24 0.03]\n",
      "  [0.42 0.24 0.05]]]\n"
     ]
    }
   ],
   "source": [
    "p_v1_h1 = multiply(p_v1_given_h1, p_h1)\n",
    "print(p_v1_h1.probs)\n",
    "print(p_v1_h1.is_valid_joint())\n",
    "\n",
    "p_v1_h1_given_h0 = multiply(p_v1_given_h0_h1, p_h1)\n",
    "print(p_v1_h1_given_h0.probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor graphs\n",
    "\n",
    "Factor graphs are bipartite graphs, with variable nodes and factor nodes. Edges can only connect nodes of different type. Consider for example:\n",
    "\n",
    "![factor_ex](imgs/factor_example.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \"\"\"\n",
    "        Initialize a node with a given name and an empty list of neighbors.\n",
    "        \n",
    "        :param name: The name of the node (string).\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.neighbors = []\n",
    "\n",
    "    def is_valid_neighbor(self, neighbor):\n",
    "        \"\"\"\n",
    "        This method should be implemented in subclasses to define valid neighbor relationships.\n",
    "        \"\"\"\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def add_neighbor(self, neighbor):\n",
    "        \"\"\"\n",
    "        Adds a neighbor to the node after checking if it is a valid connection.\n",
    "        \n",
    "        :param neighbor: The node to be added as a neighbor.\n",
    "        :raises AssertionError: If the neighbor is not valid according to is_valid_neighbor.\n",
    "        \"\"\"\n",
    "        assert self.is_valid_neighbor(neighbor)\n",
    "        self.neighbors.append(neighbor)\n",
    "\n",
    "\n",
    "class Variable(Node):\n",
    "    def is_valid_neighbor(self, factor):\n",
    "        \"\"\"\n",
    "        Checks if the given neighbor is a valid Factor.\n",
    "        \n",
    "        :param factor: The node to check.\n",
    "        :return: True if the neighbor is an instance of Factor, otherwise False.\n",
    "        \"\"\"\n",
    "        return isinstance(factor, Factor)  # Variables can only be connected to Factors\n",
    "\n",
    "\n",
    "class Factor(Node):\n",
    "    def is_valid_neighbor(self, variable):\n",
    "        \"\"\"\n",
    "        Checks if the given neighbor is a valid Variable.\n",
    "        \n",
    "        :param variable: The node to check.\n",
    "        :return: True if the neighbor is an instance of Variable, otherwise False.\n",
    "        \"\"\"\n",
    "        return isinstance(variable, Variable)  # Factors can only be connected to Variables\n",
    "\n",
    "    def __init__(self, name):\n",
    "        \"\"\"\n",
    "        Initialize a Factor node, which extends Node and contains additional data storage.\n",
    "        \n",
    "        :param name: The name of the factor node.\n",
    "        \"\"\"\n",
    "        super(Factor, self).__init__(name)\n",
    "        self.data = None  # Placeholder for storing factor-specific data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build some parsing methods in order to create a factor graph from a string representing the factorization of the joint probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "# Define a named tuple `ParsedTerm` to represent parsed terms in a structured way.\n",
    "# This will store:\n",
    "# - `term`: The main term being parsed.\n",
    "# - `var_name`: The variable name associated with the term.\n",
    "# - `given`: The conditions (if any) under which the term is considered.\n",
    "\n",
    "ParsedTerm = namedtuple('ParsedTerm', [\n",
    "    'term',      # The main term (e.g., probability expression)\n",
    "    'var_name',  # The variable name involved in the term\n",
    "    'given',     # Any conditions or dependencies (e.g., given another variable)\n",
    "])\n",
    "\n",
    "def _parse_term(term):\n",
    "    \"\"\"\n",
    "    Parses a term of the form \"(a|b,c)\" and extracts variables and conditioned-on variables.\n",
    "    \n",
    "    :param term: A string representing a probability term in the format \"(var|given1,given2,...)\" \n",
    "                 or simply \"(var)\" if there are no conditions.\n",
    "    :return: A tuple (var, given), where:\n",
    "             - var: A list of variables being considered.\n",
    "             - given: A list of variables that the term is conditioned on.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the term starts with '(' and ends with ')'\n",
    "    assert term[0] == '(' and term[-1] == ')', \"Term must be enclosed in parentheses\"\n",
    "    \n",
    "    # Extract the content inside the parentheses\n",
    "    term_variables = term[1:-1]\n",
    "\n",
    "    # Handle conditional probability notation (i.e., presence of '|')\n",
    "    if '|' in term_variables:\n",
    "        var, given = term_variables.split('|')  # Split into variable and conditions\n",
    "        var = var.split(',')  # Convert variable part into a list\n",
    "        given = given.split(',')  # Convert given (conditional) part into a list\n",
    "    else:\n",
    "        var = term_variables.split(',')  # No conditions, just split the variable(s)\n",
    "        given = []  # No conditioned-on variables\n",
    "\n",
    "    return var, given  # Return parsed variable(s) and given condition(s)\n",
    "\n",
    "\n",
    "def _parse_model_string_into_terms(model_string):\n",
    "    \"\"\"\n",
    "    Parses a model string into a list of ParsedTerm objects.\n",
    "\n",
    "    :param model_string: A string representing a probabilistic model, where \n",
    "                         terms are prefixed with 'p' (e.g., \"p(A|B)p(B)\").\n",
    "    :return: A list of ParsedTerm namedtuples, each containing:\n",
    "             - 'term': The probability expression (e.g., \"p(A|B)\").\n",
    "             - 'var_name': The main variable(s) in the term.\n",
    "             - 'given': The conditional variables (if any).\n",
    "    \"\"\"\n",
    "    \n",
    "    return [\n",
    "        ParsedTerm('p' + term, *_parse_term(term))  # Prepend 'p' to maintain original term format\n",
    "        for term in model_string.split('p')  # Split terms based on 'p' delimiter\n",
    "        if term  # Ignore empty terms from splitting\n",
    "    ]\n",
    "\n",
    "def parse_model_into_variables_and_factors(model_string):\n",
    "    \"\"\"\n",
    "    Parses a probabilistic model string into a dictionary of variables and a list of factors.\n",
    "\n",
    "    :param model_string: A string representing a probabilistic model, where terms follow the format\n",
    "                         \"p(h1)p(h2|h1)p(v1|h1)p(v2|h2)\".\n",
    "    :return: A tuple (factors, variables) where:\n",
    "             - factors: A list of Factor objects representing the relationships in the model.\n",
    "             - variables: A dictionary mapping variable names to Variable objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Parse the model string into ParsedTerm objects\n",
    "    parsed_terms = _parse_model_string_into_terms(model_string)\n",
    "    \n",
    "    # Step 2: Extract all unique variables from the model and store them in a dictionary\n",
    "    variables = {}\n",
    "\n",
    "    for parsed_term in parsed_terms:\n",
    "        # Iterate over all variables in the parsed term\n",
    "        for term in parsed_term.var_name:\n",
    "            # If the variable hasn't been seen before, create a new Variable object\n",
    "            if term not in variables:\n",
    "                variables[term] = Variable(term)\n",
    "\n",
    "    # Step 3: Create Factor objects from the parsed terms and establish neighbor relationships\n",
    "    factors = []\n",
    "    \n",
    "    for parsed_term in parsed_terms:\n",
    "        # Create a new Factor object using the full probability expression (e.g., \"p(v1|h1)\")\n",
    "        new_factor = Factor(parsed_term.term)\n",
    "\n",
    "        # Get all variable names involved in this factor (both the main variable and the given conditions)\n",
    "        all_var_names = parsed_term.var_name + parsed_term.given\n",
    "\n",
    "        for var_name in all_var_names:\n",
    "            # Connect the factor to the corresponding Variable object\n",
    "            new_factor.add_neighbor(variables[var_name])\n",
    "            # Connect the Variable object to the Factor\n",
    "            variables[var_name].add_neighbor(new_factor)\n",
    "\n",
    "        # Store the new factor\n",
    "        factors.append(new_factor)\n",
    "\n",
    "    return factors, variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine factor nodes and variable nodes to create a factor graph and add a distribution to each factor node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGM(object):\n",
    "    \"\"\"\n",
    "    Represents a Probabilistic Graphical Model (PGM) with variables and factors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, factors, variables):\n",
    "        \"\"\"\n",
    "        Initializes the PGM with a set of factors and variables.\n",
    "\n",
    "        :param factors: A list of Factor objects representing conditional dependencies.\n",
    "        :param variables: A dictionary mapping variable names to Variable objects.\n",
    "        \"\"\"\n",
    "        self._factors = factors\n",
    "        self._variables = variables\n",
    "\n",
    "    @classmethod\n",
    "    def from_string(cls, model_string):\n",
    "        \"\"\"\n",
    "        Constructs a PGM from a model string.\n",
    "\n",
    "        :param model_string: A string defining the probabilistic model, \n",
    "                             e.g., \"p(h1)p(h2|h1)p(v1|h1)p(v2|h2)\".\n",
    "        :return: An instance of PGM initialized with the parsed factors and variables.\n",
    "        \"\"\"\n",
    "        factors, variables = parse_model_into_variables_and_factors(model_string)\n",
    "        return PGM(factors, variables)\n",
    "\n",
    "    def set_distributions(self, data):\n",
    "        \"\"\"\n",
    "        Assigns probability distributions to the factors in the PGM.\n",
    "\n",
    "        :param data: A dictionary mapping factor names to probability distributions.\n",
    "                     Each entry contains a distribution with 'axes_labels' and 'probs'.\n",
    "        :raises ValueError: If a factor's expected axes do not match the provided data.\n",
    "        \"\"\"\n",
    "        var_dims = {}  # Dictionary to track variable dimensions across factors\n",
    "\n",
    "        for factor in self._factors:\n",
    "            factor_data = data[factor.name]  # Retrieve the corresponding data distribution\n",
    "\n",
    "            # Ensure that all expected axes (variables) are present in the data\n",
    "            if set(factor_data.axes_labels) != set(v.name for v in factor.neighbors):\n",
    "                missing_axes = set(v.name for v in factor.neighbors) - set(data[factor.name].axes_labels)\n",
    "                raise ValueError(\"data[{}] is missing axes: {}\".format(factor.name, missing_axes))\n",
    "\n",
    "            # Check and store variable dimensions to ensure consistency\n",
    "            for var_name, dim in zip(factor_data.axes_labels, factor_data.probs.shape):\n",
    "                if var_name not in var_dims:\n",
    "                    var_dims[var_name] = dim  # Store dimension for the first time\n",
    "                elif var_dims[var_name] != dim:\n",
    "                    raise ValueError(\n",
    "                        \"data[{}] axes is wrong size, {}. Expected {}\".format(\n",
    "                            factor.name, dim, var_dims[var_name]\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            # Assign the data to the factor\n",
    "            factor.data = data[factor.name]\n",
    "\n",
    "    def variable_from_name(self, var_name):\n",
    "        \"\"\"\n",
    "        Retrieves a Variable object by its name.\n",
    "\n",
    "        :param var_name: The name of the variable to retrieve.\n",
    "        :return: The corresponding Variable object.\n",
    "        \"\"\"\n",
    "        return self._variables[var_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that, in the previous example, we can write the marginal as a combination of sums and products:\n",
    "\n",
    "$$p(x_5) = \\sum_{x_1, x_2, x_3, x_4}p(x_1, x_2, x_3, x_4, x_5) =\\\\ = \\sum_{x_3, x_4}f_3(x_3,x_4,x_5)\\bigg[\\sum_{x_1}f_1(x_1, x_3)\\bigg]\\bigg[\\sum_{x_2}f_2(x_2, x_3)\\bigg]$$\n",
    "\n",
    "and interpret them as messages flowing from factors to variables (including a summation) or from variables to factors (via multiplication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Messages(object):\n",
    "    \"\"\"\n",
    "    Handles message passing in a probabilistic graphical model.\n",
    "    Implements variable-to-factor and factor-to-variable message computations \n",
    "    for belief propagation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes an empty dictionary to store messages between variables and factors.\n",
    "        \"\"\"\n",
    "        self.messages = {}\n",
    "\n",
    "    def _variable_to_factor_messages(self, variable, factor):\n",
    "        \"\"\"\n",
    "        Computes the message from a variable to a factor.\n",
    "        \n",
    "        :param variable: The Variable object sending the message.\n",
    "        :param factor: The Factor object receiving the message.\n",
    "        :return: The computed message (a probability distribution).\n",
    "        \n",
    "        - The message is computed as the product of all incoming messages to the variable,\n",
    "          excluding messages coming from the factor itself.\n",
    "        - If no messages exist (base case), return a uniform distribution (or 1).\n",
    "        \"\"\"\n",
    "        # TODO: Implement message computation logic here.\n",
    "        return \n",
    "\n",
    "    def _factor_to_variable_messages(self, factor, variable):\n",
    "        \"\"\"\n",
    "        Computes the message from a factor to a variable.\n",
    "        \n",
    "        :param factor: The Factor object sending the message.\n",
    "        :param variable: The Variable object receiving the message.\n",
    "        :return: The computed message (a probability distribution).\n",
    "        \n",
    "        - The message is computed by multiplying the factor's probability distribution\n",
    "          with all incoming messages from other neighboring variables.\n",
    "        - The result is then marginalized over all variables except the target variable.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create a deep copy of the factor's distribution to avoid modifying the original\n",
    "        factor_dist = Distribution(factor.data.probs, factor.data.axes_labels)\n",
    "\n",
    "        for neighbor_variable in factor.neighbors:\n",
    "            if neighbor_variable.name == variable.name:\n",
    "                continue  # Skip the target variable itself\n",
    "\n",
    "            # Retrieve the incoming message from the variable to the factor and multiply\n",
    "            # TODO: Implement message retrieval and multiplication here\n",
    "\n",
    "        # Sum over all axes except for the target variable to marginalize them out\n",
    "        # TODO: Implement marginalization here\n",
    "\n",
    "        return \n",
    "\n",
    "    def marginal(self, variable):\n",
    "        \"\"\"\n",
    "        Computes the marginal probability distribution of a variable.\n",
    "        \n",
    "        :param variable: The Variable object whose marginal is being computed.\n",
    "        :return: The normalized marginal probability distribution.\n",
    "        \n",
    "        - The marginal is proportional to the product of all incoming messages to the variable.\n",
    "        - The result is then normalized to ensure it represents a valid probability distribution.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Implement marginal computation logic here\n",
    "\n",
    "        # Normalize the resulting probability distribution before returning\n",
    "        return \n",
    "\n",
    "    def variable_to_factor_messages(self, variable, factor):\n",
    "        \"\"\"\n",
    "        Retrieves or computes the message from a variable to a factor.\n",
    "        \n",
    "        :param variable: The Variable object sending the message.\n",
    "        :param factor: The Factor object receiving the message.\n",
    "        :return: The computed or cached message.\n",
    "        \"\"\"\n",
    "        message_name = (variable.name, factor.name)\n",
    "        \n",
    "        if message_name not in self.messages:\n",
    "            self.messages[message_name] = self._variable_to_factor_messages(variable, factor)\n",
    "\n",
    "        return self.messages[message_name]\n",
    "\n",
    "    def factor_to_variable_message(self, factor, variable):\n",
    "        \"\"\"\n",
    "        Retrieves or computes the message from a factor to a variable.\n",
    "        \n",
    "        :param factor: The Factor object sending the message.\n",
    "        :param variable: The Variable object receiving the message.\n",
    "        :return: The computed or cached message.\n",
    "        \"\"\"\n",
    "        message_name = (factor.name, variable.name)\n",
    "        \n",
    "        if message_name not in self.messages:\n",
    "            self.messages[message_name] = self._factor_to_variable_messages(factor, variable)\n",
    "\n",
    "        return self.messages[message_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to build the following factor graph:\n",
    "\n",
    "![factor1](imgs/factor2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_h1 = Distribution(np.array([[0.2], [0.8]]), ['h1'])\n",
    "p_h2_given_h1 = Distribution(np.array([[0.5, 0.2], [0.5, 0.8]]), ['h2', 'h1'])\n",
    "p_v1_given_h1 = Distribution(np.array([[0.6, 0.1], [0.4, 0.9]]), ['v1', 'h1'])\n",
    "p_v2_given_h2 = Distribution(p_v1_given_h1.probs, ['v2', 'h2'])\n",
    "\n",
    "pgm = PGM.from_string(\"p(h1)p(h2|h1)p(v1|h1)p(v2|h2)\")\n",
    "\n",
    "pgm.set_distributions({\n",
    "    \"p(h1)\": p_h1,\n",
    "    \"p(h2|h1)\": p_h2_given_h1,\n",
    "    \"p(v1|h1)\": p_v1_given_h1,\n",
    "    \"p(v2|h2)\": p_v2_given_h2,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compute the marginal distribution $p(v_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23, 0.77])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgm = PGM.from_string(\"p(h1)p(h2|h1)p(v1|h1)p(v2|h2)\")\n",
    "\n",
    "pgm.set_distributions({\n",
    "    \"p(h1)\": p_h1,\n",
    "    \"p(h2|h1)\": p_h2_given_h1,\n",
    "    \"p(v1|h1)\": p_v1_given_h1,\n",
    "    \"p(v2|h2)\": p_v2_given_h2,\n",
    "})\n",
    "\n",
    "m = Messages()\n",
    "m.marginal(pgm.variable_from_name('v2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('p(h1)', 'h1'): array([0.2, 0.8]),\n",
       " ('v1', 'p(v1|h1)'): 1.0,\n",
       " ('p(v1|h1)', 'h1'): array([1., 1.]),\n",
       " ('h1', 'p(h2|h1)'): array([0.2, 0.8]),\n",
       " ('p(h2|h1)', 'h2'): array([0.26, 0.74]),\n",
       " ('h2', 'p(v2|h2)'): array([0.26, 0.74]),\n",
       " ('p(v2|h2)', 'v2'): array([0.23, 0.77])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.marginal(pgm.variable_from_name('v1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "(From Bayesian Reasoning and Machine Learning, David Barber) You live in a house with three rooms, labelled 1, 2, 3. There is a door between rooms 1 and 2 and another between rooms 2 and 3. One cannot directly pass between rooms 1 and 3 in one time-step. An annoying fly is buzzing from one room to another and there is some smelly cheese in room 1 which seems to attract the fly more. Using $x_t$ for which room the fly is in at time t, with $dom(x_t) = {1,2,3}$, the movement of the fly can be described by a transition:\n",
    "$p(x_{t+1} = i|x_t = j) = M_{ij}$\n",
    "\n",
    "where M is a transition matrix:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.7 & 0.5 & 0 \\\\\n",
    "0.3 & 0.3 & 0.5 \\\\\n",
    "0 & 0.2 & 0.5 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Given that the fly is in room 1 at time 1, what is the probability of room occupancy at time t = 5? Assume a Markov chain which is defined by the joint distribution\n",
    "\n",
    "$p(x_1, . . . , x_T ) = p(x_1) \\prod p(x_{t+1}|x_t)$\n",
    "\n",
    "We are asked to compute $p(x_5|x_1 = 1)$ which is given by\n",
    "$\\sum p(x_5|x_4)p(x_4|x_3)p(x_3|x_2)p(x_2|x_1 = 1)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Hidden Markov Models\n",
    "\n",
    "Imagine you're trying to guess someone's mood without directly asking them or using brain electrodes. Instead, you observe their facial expressions, whether they're smiling or frowning, to make an educated guess.\n",
    "\n",
    "We assume moods can be categorized into two states: good and bad. When you meet someone for the first time, there's a 70% chance they're in a good mood and a 30% chance they're in a bad mood.\n",
    "\n",
    "If someone is in a good mood, there's an 80% chance they'll stay in a good mood and a 20% chance they'll switch to a bad mood over time. The same probabilities of switching the mood apply if they start in a bad mood.\n",
    "\n",
    "Lastly, when someone is in a good mood, they're 90% likely to smile and 10% likely to frown. Conversely, if they're in a bad mood, they have a 10% chance of smiling and a 90% chance of frowning.\n",
    "\n",
    "The transitions are summarized in the following graph.\n",
    "\n",
    "Your task is to use these probabilities to figure out the first and second hidden mood states (the probability that the first mood is good/bad and the probability that the second mood is good/bad) based on the observable facial expressions you see (imagine you see the sequence [smiling, frowning]).\n",
    "\n",
    "![factor1](imgs/mood.png)\n",
    "(image by Y. Natsume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
